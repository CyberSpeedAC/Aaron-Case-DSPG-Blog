[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aaron Case DSPG Blog",
    "section": "",
    "text": "AI/Local Food Week 3 Wrap Up\n\n\n\n\n\n\n\nWeek Three\n\n\nWrap Up\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2023\n\n\nAaron C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek Three\n\n\n\n\n\n\n\nWeek Three\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nAaron Case\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek Three Research\n\n\n\n\n\n\n\nWeek Three\n\n\nResearch\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nAaron Case\n\n\n\n\n\n\n  \n\n\n\n\nWeek Three Spiders\n\n\n\n\n\n\n\nWeek Three\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2023\n\n\nAaron Case\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek Two\n\n\n\n\n\n\n\nWeek Two\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2023\n\n\nAaron Case\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImporting Census Data\n\n\n\n\n\n\n\nWeek Two\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\nMay 26, 2023\n\n\nAaron Case\n\n\n\n\n\n\n  \n\n\n\n\nWeek One\n\n\n\n\n\n\n\nWeek One\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nAaron Case\n\n\n\n\n\n\n  \n\n\n\n\nCensus Visual\n\n\n\n\n\n\n\nWeek Two\n\n\nCode\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nAaron Case\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Aaron_C_Week1/Aaron_C_Week1.html",
    "href": "posts/Aaron_C_Week1/Aaron_C_Week1.html",
    "title": "Week One",
    "section": "",
    "text": "Week One\nDuring week one my week goal is to learn as much as possible about Python and R in Datacamp\nLessons completed:\n\nIntroduction to R\nIntermediate R\nCleaning Data in R\nIntroduction to Python\nIntermediate Python\nData Manipulation with pandas\nAI Fundamentals\nGitHub Concepts\n\nAlso during week one I did a debriefing of project with the Employer."
  },
  {
    "objectID": "posts/Aaron_C_Week2/Aaron_C_Week2.html",
    "href": "posts/Aaron_C_Week2/Aaron_C_Week2.html",
    "title": "Week Two",
    "section": "",
    "text": "For week two my goal was to continue to learn in Datacamp\nLessons completed:\n\nWriting Efficient Python Code\nWeb Scraping in Python\n\nI also learned how to visualize data using Tidycensus with the American Community Survey Data"
  },
  {
    "objectID": "posts/Aaron_C_Week2/Importing Census Data.html",
    "href": "posts/Aaron_C_Week2/Importing Census Data.html",
    "title": "Importing Census Data",
    "section": "",
    "text": "Since I needed to extract a large amount of data from the American Community Survey (ASC) and convert it into a CSV file. In light of this I wrote this code to extract ASC data from the table codes. The Code takes in a list of names that you want the file name to be. Along with the corresponding table code. It also takes in a folder name. It then makes (if needed) and adds the CVS files to the specified folder (For a clean directory). Its important to note that where you run the R file is where a folder is made. I made this with the intentions of it being editable (and hopefully user friendly).\n\n####################\n#  Inserting Data  #\n####################\n\n\nfolder <- \"Folder_Name_Here\" # <---------- Change this value FIRST!\n\nACSList <- c(\n    # \"Data Name\",\"DataCode\", \n    # ...\n  ) \nACSListToCSV(ACSList,folder)\n\n\n##########################################\n#  Global Variables That can be Changed  #\n##########################################\n\n#To change the get_acs() geography variable\ngeographyType <- \"county\"\n\n#To change the get_acs() servay variable\nservayType <- \"ACS5\"\n\n#Change to NULL if no state\nstateType <- \"IA\"\n\n#This will make a geometry file as well if TRUE\nwithGeometry <- FALSE\n\n#checking the year\nyear = NULL\n\n###################################\n#  Functions that make life easy  #\n###################################\n\n#Imports \nlibrary(tidycensus) #For ACS extractions\nlibrary(stringi) #For folderNameFixer()\nlibrary(tigris)\noptions(tigris_use_cache = TRUE)\n\n\n#File name changers. This will set the name of the file. Feel free to edit this\nrenameFile <- function(tableTitle, tableCode, isGeometric){\n  fileName <- paste(tableTitle, \" (\", tableCode, sep='')\n  if(isGeometric){\n    fileName = paste(fileName, \", \",capFirst(\"tract\"), sep='')\n  } else {\n    fileName = paste(fileName, \", \",capFirst(geographyType), sep='')\n  }\n  if(is.null(stateType) == FALSE){\n    fileName = paste(fileName, \", \", stateType, sep='')\n  }\n  if(is.null(year) == FALSE){\n    fileName = paste(fileName, \", \", year, sep='')\n  }\n  fileName = paste(fileName, \", \", servayType, sep='')\n  if(isGeometric){\n    fileName = paste(fileName, \", Geometry).csv\", sep='')\n  } else {\n    fileName = paste(fileName, \").csv\", sep='')\n  }\n  return(fileName)\n}\n\n#ACS extractions.\n#Feel free to add to this list.\ngeoACSDataFrame = function(tableCode){\n  get_acs(\n    #Add Changes here\n    geography = \"tract\",\n    table = tableCode,\n    servay = servayType,\n    state = stateType,\n    geometry = TRUE\n  )\n}\n\ndefaultACSDataFrame = function(tableCode){\n  get_acs(\n    #Add Changes here\n    geography = geographyType,\n    table = tableCode,\n    servay = servayType,\n    state = stateType\n  )\n}\n\n#Conditions for files fell free to edit this\nfileImplications <- function(tableTitle, tableCode){\n  #Add a condition and apply both the ACS extraction and the File name changer\n  #Example\n  if(withGeometry){\n    fileName <- renameFile(tableTitle, tableCode, TRUE)\n    #output with Geometry\n    dataToCSV(geoACSDataFrame(tableCode), fileName)\n  }\n  \n  fileName <- renameFile(tableTitle, tableCode, FALSE)\n  #Default\n  #This Makes the CSV File\n  #format dataToCSV(your ACS DataFrame, File name changer() )\n  dataToCSV(defaultACSDataFrame(tableCode), fileName)\n}\n\n\n#For clarity capitalizes the first letter in a string and lowercases the rest (Feel free to Use)\ncapFirst = function(xStr){\n   paste(toupper(substring(xStr, 1, 1)), tolower(substring(xStr, 2, nchar(xStr))), sep = \"\")\n}\n#Validates and fixes folder name string (Feel free to edit)\nnameFixer <- function(xStr, fixType){\n  #Replaces bad characters with ''\n  xStr <- stri_replace_all_regex(xStr, \n                         pattern=c('/', ':', '\\\\*', '\"', '<', '>', '\\\\|'),\n                         replacement=c('-', '', '', '', '', '', ''),\n                         vectorize=FALSE)\n  if(xStr == \"\"){\n    if(capFirst(fixType) == \"Folder\"){\n      print(\"Ops the folder name has all bad characters lets fix that\")\n      xStr <- \"New_Data_Folder\"\n    }\n    else{\n      print(\"Ops the file name has all bad characters lets fix that\")\n      xStr <- \"New_Data_file\"\n    }\n  }\n  return(xStr)\n}\n#For bulk downloading tables\nACSListToCSV <- function(bulkArray, folder){\n  if(length(bulkArray) %% 2){\n    #Scream if array is odd length. We don't need any mistakes!\n    print(\"Somethings Missing. List format should be like c( Data Name, DataCode, ... )\")\n    return(\"ERROR\")\n  }\n  #Validates folder name\n  folder <- nameFixer(folder, \"Folder\")\n  #Makes a folder if needed\n  if(!file.exists(folder)){\n    dir.create(folder)\n    print(\"New Folder Made Adding Files\")\n  }\n  index <- 1\n  #Adds files\n  while(index < length(bulkArray)){\n    fileImplications(nameFixer(bulkArray[index], \"File\"), bulkArray[index+1]) # (title , code)\n    index <- index + 2\n  }\n  print(\"All Files have been downloaded\")\n}\n#ACS Data frame to CSV file\ndataToCSV <- function(data, fileName){\n  #This adds the file to the folder\n  path <- paste(\".\\\\\",folder,\"\\\\\", fileName, sep='')\n  #Makes the CSV\n  write.csv(data, path)\n  print(paste(\"Added File:\",fileName))\n}"
  },
  {
    "objectID": "posts/Aaron_C_Week2/TidyCensusOverview.html",
    "href": "posts/Aaron_C_Week2/TidyCensusOverview.html",
    "title": "Census Visual",
    "section": "",
    "text": "Both a bar plot, and chorpleth map were made from the American Community Survey (ASC) data using Tidycensus library in R.\n\n#Imports for both Graph and Map\nlibrary(tidycensus)\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(plotly)\nlibrary(ggiraph) \n\n#Grabing median_income for bar blot\nmedian_income <- get_acs(\n  geography = \"county\",\n  variables = \"B19013_001\",\n  state = \"IA\", \n  year = 2021\n)\n\n#View the mid range of countys mean income\nmedian_income_data <- median_income %>%\n  #reducing the number of countys the graph can display\n  slice(floor(99 * 0.25):floor(99 * 0.75)+1) %>%\n  #ordering from estimate highest to estimate lowest\n  arrange(desc(estimate))\n\n#The Bar plot\nmd_bar_plot <- ggplot(median_income_data, aes(x = estimate, \n                                    y = reorder(NAME, estimate),\n                                    tooltip = estimate,\n                                    data_id = GEOID)) +\n  #Generating the error bars\n  geom_errorbar(aes(xmin = estimate - moe, \n                    xmax = estimate + moe),\n                    width = 0.5, \n                    size = 1) + \n  #Coloring the estimate dot \n  geom_point_interactive(color = \"darkblue\", size = 1.5) +\n  #Bottom Label range\n  scale_x_continuous(labels = label_dollar()) + \n  #County names and removing the Unnecessary words\n  scale_y_discrete(labels = function(x) str_remove(x, \" County, Iowa|, Iowa\")) +\n  #Graph labeling for views convince \n  labs(title = \"Median Income 2021 ACS\",\n       #subtitle = \"Counties in Iowa\",\n       caption = \"Data acquired with R and tidycensus. \\nError bars represent margin of error around estimates of Median income.\",\n       x = \"ACS Estimate Mean Income\",\n       y = \"Counties in Iowa\") + \n  #Text Sizing\n  theme_minimal(base_size = 8)\n#Making the graph interactive\nmd_bar_plot_interactive <- girafe(ggobj = md_bar_plot) %>% girafe_options(opts_hover(css = \"fill:purple;\"))\n\n#The Map\nmedian_income_map <- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  state = \"IA\",\n  year = 2021,\n  geometry = TRUE\n)\n# The Map\nmd_chorpleth_map <- ggplot(median_income_map, aes(fill = estimate)) + \n  #The map display\n  geom_sf() + \n  #Empty theme of the map\n  theme_void() + \n  #Colors the map \n  scale_fill_viridis_c(option = \"G\", n.breaks = 10) + \n  #Information\n  labs(title = \"Median Income by Census track\",\n       subtitle = \"\",\n       fill = \"ACS estimates\",\n       caption = \"Median Income by ACS tidycensus R package in 2021\")\n\n\n#This renders the bar plot \nmd_bar_plot_interactive\n\n#This renders the chorpleth map\nmd_chorpleth_map\n\n\n\n\nBar Plot\n\n\n\n\n\nChorpleth Map"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Aaron_C_Week3.html",
    "href": "posts/Aaron_C_Week3/Aaron_C_Week3.html",
    "title": "Week Three",
    "section": "",
    "text": "This week was dedicated to collecting data and doing research for our project. It was also spent to learn how to webscrapers (Spiders). At the end of the week was tasked to presented the Week three wrap up for our team.\nData Camp Lessons completed:\n\nWriting Efficient R Code\n\nWeek Three Research\nWeek Three Spider\nWeek Three Wrap Up"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_Research.html",
    "href": "posts/Aaron_C_Week3/Week3_Research.html",
    "title": "Week Three Research",
    "section": "",
    "text": "Farmers Market Prices:\nAt the 2015 PFI Annual Conference, Kay Jensen collected farmers’ vegetable prices. Recent data shows price ranges for tomatoes, ranging from $2.50 to $4 per pound.\nExpatistan:\nTells the price of 1 kg (2 lb.) of tomatoes in Des Moines IA can be used to find other prices located in IA.\nAgMRC:\nProvides a some detailed and helpful references for tomatoes.\nMarket Maker:\nA potential source to find and locate local farmers that grow Heirloom Tomatoes.\nLocal Harvest:\nA potential source to find and locate local farmers that grow Heirloom Tomatoes.\nPractical farmers:\nA potential source to find and locate local farmers that grow Heirloom Tomatoes.\nInstacart:\nA cite that could be of use to find Items.\nNFMD:\nMarket on Central - Farmers Market in Historic Downtown Fort Dodge\nNational Retail Report - Specialty Crops ( USDA Fruits & Vegetables Market Report ):\nAdvertised Prices for Specialty Crops at Major Retail Supermarket Outlets it contains Heirloom Tomatoes but only specifies the Midwest U.S.\nFRED Economic Data:\nContains the average Price of Tomatoes( Tomatoes, Field Grown (Cost per Pound/453.6 Grams) in U.S. City Average) All fresh field grown and vine ripened round red tomatoes. Includes organic and non-organic.\nFarmers Market Nutrition Program:\nLists farmers markets in Iowa\nIowa Food Cooperative (Iowa Food Coop):\nContains some data that could be useful\nNASS Eggs:\nContains tons of data that could be useful\nList of Egg Farms in Iowa:\ncould be useful to source eggs"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_Research.html#heirloom-tomatoes",
    "href": "posts/Aaron_C_Week3/Week3_Research.html#heirloom-tomatoes",
    "title": "Week Three Research",
    "section": "Heirloom Tomatoes",
    "text": "Heirloom Tomatoes\nPlaces that might use Heirloom Tomatoes\n\nJava House\n\nStores that sell Heirloom Tomatoes that we can collect data from\n\nGateway market\nRuss’s Market\nFresh thyme\nHy-Vee\nNew Pioneer coop\n\nInvestigated Stores\n\nDogpatch: They have seeds but no tomatoes for sale\nFairway: They don’t have any heirloom tomatoes for sale\nWalmart: They have seeds but no tomatoes for sale\nTarget: They don’t have any heirloom tomatoes for sale\nCostco: They don’t have any heirloom tomatoes for sale\nWhole Foods Market: They don’t have any heirloom tomatoes for sale in Iowa\nAldi: They don’t have any heirloom tomatoes for sale\nTrader Joe’s: They don’t have any heirloom tomatoes for sale\nCampbell’s Nutrition: They don’t have any heirloom tomatoes for sale\nRamsey’s Market: They don’t have any heirloom tomatoes for sale\nGoPuff: They don’t have any heirloom tomatoes for sale\nOver 150+ Other Websites searched"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_Research.html#egg",
    "href": "posts/Aaron_C_Week3/Week3_Research.html#egg",
    "title": "Week Three Research",
    "section": "EGG",
    "text": "EGG\nStores that sell Eggs that we can collect data from\n\nGateway market\nRuss’s Market\nFresh Thyme Market\nHv-Vee\nNew Pioneer coop\ndogpatch\nFairway\nwalmart\nTarget\nWhole Foods Market\nAldi\nTrader Joe’s\nRamsey’s Market\nGoPuff"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_Research.html#bacon",
    "href": "posts/Aaron_C_Week3/Week3_Research.html#bacon",
    "title": "Week Three Research",
    "section": "Bacon",
    "text": "Bacon\nStores that sell Bacon that we can collect data from\n\nGateway market\nRuss’s Market\nFresh Thyme Market\nHv-Vee\nNew Pioneer coop\ndogpatch\nFairway\nWalmart\nTarget\nCostco\nWhole Foods Market\nAldi\nTrader Joe’s\nRamsey’s Market\nGoPuff"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_Spider.html",
    "href": "posts/Aaron_C_Week3/Week3_Spider.html",
    "title": "Week Three Spiders",
    "section": "",
    "text": "During week the I started to developing spiders to extract data from webpages. This example is capable from extracting data from the privided weblink and putting the data into a pandas data frame. However this example is nowhere near finished.\n\nimport pandas as pd\nimport scrapy\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy.utils.log import configure_logging\n\nclass FreshThymeBaconSpider(scrapy.Spider):\n    name = 'Fresh Thyme Market Bacon Spider'\n\n    def start_requests( self ):\n        start_urls = ['https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage']\n        for url in start_urls:\n            yield scrapy.Request( url = url, callback = self.cardsParse)\n    \n    def cardsParse(self, response):\n        #Fail safe for links\n        try:\n            #grabs all cards from list and saves the link to follow\n            xpath = '//*[contains(@class,\"Listing\")]/div/a/@href'\n            listCards = response.xpath(xpath)\n            linklist.append(listCards.extract())\n            for url in listCards:\n                yield response.follow( url = url, callback = self.itemParse, meta={'link': url} )\n        except AttributeError:\n           pass\n    \n    def itemParse(self, response):\n        #xpaths to the name and price\n        nameXpath = '//*[contains(@class, \"PdpInfoTitle\")]/text()'\n        priceXpath = '//*[contains(@class, \"PdpMainPrice\")]/text()'\n        url = response.meta.get('link')\n        #Grabs the name and price from the xpaths and adds them to the bacon list\n        bacon.append({'bacon': response.xpath(nameXpath).extract(), 'price': response.xpath(priceXpath).extract()})\n\n# Start\nconfigure_logging()\nbacon = []\nlinklist = []\nprocess = CrawlerProcess()\nprocess.crawl(FreshThymeBaconSpider)\nprocess.start()\nprocess.stop()\nbaconFrame = pd.DataFrame(bacon)\nprint(baconFrame)\n\n2023-06-02 13:59:15 [scrapy.utils.log] INFO: Scrapy 2.6.2 started (bot: scrapybot)\n\n\n2023-06-02 13:59:15 [scrapy.utils.log] INFO: Versions: lxml 4.9.1.0, libxml2 2.9.14, cssselect 1.1.0, parsel 1.6.0, w3lib 1.21.0, Twisted 22.2.0, Python 3.10.9 | packaged by conda-forge | (main, Jan 11 2023, 15:15:40) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 22.0.0 (OpenSSL 1.1.1s  1 Nov 2022), cryptography 37.0.1, Platform Windows-10-10.0.19044-SP0\n\n\n2023-06-02 13:59:15 [scrapy.crawler] INFO: Overridden settings:\n{}\n\n\n2023-06-02 13:59:15 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n\n\n2023-06-02 13:59:15 [scrapy.extensions.telnet] INFO: Telnet Password: c5df1fb3cf48c019\n\n\n2023-06-02 13:59:15 [scrapy.middleware] INFO: Enabled extensions:\n['scrapy.extensions.corestats.CoreStats',\n 'scrapy.extensions.telnet.TelnetConsole',\n 'scrapy.extensions.logstats.LogStats']\n\n\n2023-06-02 13:59:16 [scrapy.middleware] INFO: Enabled downloader middlewares:\n['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n\n\n2023-06-02 13:59:16 [scrapy.middleware] INFO: Enabled spider middlewares:\n['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n\n\n2023-06-02 13:59:16 [scrapy.middleware] INFO: Enabled item pipelines:\n[]\n\n\n2023-06-02 13:59:16 [scrapy.core.engine] INFO: Spider opened\n\n\n2023-06-02 13:59:17 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n\n\n2023-06-02 13:59:17 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n\n\n2023-06-02 13:59:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage> (referer: None)\n\n\n2023-06-02 13:59:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-uncured-turkey-bacon-00042421130669> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/fresh-thyme-smoked-sliced-uncured-bacon-00841330117590> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/farm-promise-smoked-applewood-uncured-bacon-00070919021595> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-bacon-in-bag-00201120000004> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/farm-promise-smoked-hardwood-uncured-bacon-00070919021601> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-applewood-bacon-in-bag-00201121000003> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-uncured-hickory-smoked-sunday-bacon-00025317101004> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-peppered-bacon-00201267000004> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-applewood-bacon-00201249000008> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-canadian-style-uncured-bacon-00042421500875> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/fresh-thyme-smoked-sliced-uncured-turkey-bacon-00841330117606> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-bacon-00201247000000> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-hot-smoked-uncured-sausage-00042421003659> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/pedersons-natural-farms-organic-no-sugar-uncured-smoked-bacon-00641227601405> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/hatfield-hardwood-smoked-uncured-bacon-00070919021564> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-fully-cooked-traditional-bacon-00042421014808> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-naturally-smoked-traditional-bacon-00042421225792> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-breakfast-turkey-sausage-00042421130799> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-bratwurst-00042421246803> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-breakfast-chicken-sausage-links-00042421140286> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-all-natural-honeycrisp-apple-chicken-sausages-00042421140187> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-all-natural-robust-italian-chicken-sausages-00042421140132> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-all-natural-chorizo-chicken-sausages-00042421140255> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/boars-head-all-natural-breakfast-pork-sausage-00042421140293> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-organic-wild-mushrooms-with-italian-herbs-chicken-sausage-00071728071207> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-organic-spinach-&-spring-greens-chicken-sausage-00071728071009> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-antibiotic-free-tomato-basil-&-chicken-zesty-italian-style-blended-sausage-00071728070057> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-organic-mild-italian-with-bell-peppers-chicken-sausage-00071728071153> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-antibiotic-free-spinach-&-chicken-garlic-seasoned-blended-sausage-00071728070002> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/bilinskis-antibiotic-free-cajun-style-chicken-&-peppers-blended-sausage-00071728070408> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/beyond-meat-beyond-sausage-plantbased-original-brat-links-00852629004774> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/beyond-meat-beyond-sausage-hot-italian-style-plantbased-sausages-00852629004750> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-uncured-turkey-hot-dogs-00025317775205> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/beddar-cheddar-00077782023930> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-uncured-beef-hot-dog-00025317775304> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-chicken-&-sage-breakfast-sausage-00025317006972> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-classic-pork-breakfast-sausage-00025317693004> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-gluten-free-uncured-beef-corn-dogs-00025317007214> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-naturals-do-good-dog-uncured-beef-hot-dogs-6ct-00025317218603> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-great-organic-uncured-beef-hot-dog-00025317775700> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/apple-bulk-chicken-sausage-00201465000004> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/andouille-sausage-00077782026979> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/pedersons-natural-farms-no-sugar-uncured-hickory-bacon-00641227301404> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/indiana-kitchen-hardwood-smoked-thick-cut-bacon-00759199801249> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/deli-sliced-thick-cut-peppered-bacon-in-bag-00201122000002> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/indiana-kitchen-hardwood-smoked-bacon-00759199801171> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/fresh-thyme-fully-cooked-uncured-turkey-bacon-00841330115077> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://ww2.freshthyme.com/sm/planning/rsid/951/product/applegate-organics-uncured-hickory-smoked-turkey-bacon-00025317122009> (referer: https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage)\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] INFO: Closing spider (finished)\n\n\n2023-06-02 13:59:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 21280,\n 'downloader/request_count': 49,\n 'downloader/request_method_count/GET': 49,\n 'downloader/response_bytes': 15558006,\n 'downloader/response_count': 49,\n 'downloader/response_status_count/200': 49,\n 'elapsed_time_seconds': 6.895619,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(2023, 6, 2, 18, 59, 23, 901878),\n 'httpcompression/response_bytes': 46584003,\n 'httpcompression/response_count': 49,\n 'log_count/DEBUG': 50,\n 'log_count/INFO': 10,\n 'request_depth_max': 1,\n 'response_received_count': 49,\n 'scheduler/dequeued': 49,\n 'scheduler/dequeued/memory': 49,\n 'scheduler/enqueued': 49,\n 'scheduler/enqueued/memory': 49,\n 'start_time': datetime.datetime(2023, 6, 2, 18, 59, 17, 6259)}\n\n\n2023-06-02 13:59:23 [scrapy.core.engine] INFO: Spider closed (finished)\n\n\n                                                bacon            price\n0       [Boar's Head Uncured Turkey Bacon - 12 Ounce]          [$6.99]\n1   [Fresh Thyme Smoked Sliced Uncured Bacon - 12 ...          [$6.49]\n2   [Farm Promise Smoked Applewood Uncured Bacon -...          [$6.99]\n3      [Deli Sliced Thick Cut Bacon In Bag - 3 Pound]  [$17.97 avg/ea]\n4   [Farm Promise Smoked Hardwood Uncured Bacon - ...          [$6.99]\n5   [Deli Sliced Thick Cut Applewood Bacon In Bag ...  [$17.97 avg/ea]\n6   [Applegate Naturals Uncured Hickory Smoked Sun...          [$6.49]\n7    [Deli Sliced Thick Cut Peppered Bacon - 1 Pound]   [$5.99 avg/ea]\n8   [Deli Sliced Thick Cut Applewood Bacon - 1 Pound]   [$5.99 avg/ea]\n9   [Boar's Head Canadian Style Uncured Bacon - 6 ...          [$5.99]\n10  [Fresh Thyme Smoked Sliced Uncured Turkey Baco...          [$4.69]\n11            [Deli Sliced Thick Cut Bacon - 1 Pound]   [$5.99 avg/ea]\n12  [Boar's Head Hot Smoked Uncured Sausage - 16 O...          [$7.99]\n13  [Pederson's Natural Farms Organic No Sugar Unc...          [$7.49]\n14  [Hatfield Hardwood Smoked Uncured Bacon - 16 O...          [$6.99]\n15  [Boar's Head Fully Cooked Traditional Bacon - ...          [$7.49]\n16  [Boar's Head Naturally Smoked Traditional Baco...          [$7.99]\n17   [Boar's Head Breakfast Turkey Sausage - 6 Ounce]          [$4.99]\n18                 [Boar's Head Bratwurst - 16 Ounce]          [$8.29]\n19  [Boar's Head Breakfast Chicken Sausage Links -...          [$5.99]\n20  [Boar's Head All Natural Honeycrisp Apple Chic...          [$7.99]\n21  [Boar's Head All Natural Robust Italian Chicke...          [$8.99]\n22  [Boar's Head All Natural Chorizo Chicken Sausa...          [$8.99]\n23  [Boar's Head All Natural Breakfast Pork Sausag...          [$4.99]\n24  [Bilinski's Organic Wild Mushrooms With Italia...          [$7.49]\n25  [Bilinski's Organic Spinach & Spring Greens Ch...          [$7.49]\n26  [Bilinski's Antibiotic Free Tomato Basil & Chi...          [$4.49]\n27  [Bilinski's Organic Mild Italian With Bell Pep...          [$7.49]\n28  [Bilinski's Antibiotic Free Spinach & Chicken ...          [$4.49]\n29  [Bilinski's Antibiotic Free Cajun Style Chicke...          [$4.49]\n30  [Beyond Meat Beyond Sausage Plant-based Origin...          [$6.99]\n31  [Beyond Meat Beyond Sausage Hot Italian Style ...          [$6.99]\n32  [Applegate Naturals Uncured Turkey Hot Dogs - ...          [$5.99]\n33                        [Beddar Cheddar - 14 Ounce]          [$4.99]\n34  [Applegate Naturals Uncured Beef Hot Dog - 10 ...          [$5.79]\n35  [Applegate Naturals Chicken & Sage Breakfast S...          [$4.99]\n36  [Applegate Naturals Classic Pork Breakfast Sau...          [$4.99]\n37  [Applegate Naturals Gluten Free Uncured Beef C...          [$6.99]\n38  [Applegate Naturals Do Good Dog Uncured Beef H...          [$7.99]\n39  [Applegate Great Organic Uncured Beef Hot Dog ...          [$8.99]\n40             [Apple Bulk Chicken Sausage - 1 Pound]   [$3.99 avg/ea]\n41                   [Andouille Sausage - 13.5 Ounce]          [$4.99]\n42  [Pederson's Natural Farms No Sugar Uncured Hic...          [$7.49]\n43  [Indiana Kitchen Hardwood Smoked Thick Cut Bac...          [$5.49]\n44  [Deli Sliced Thick Cut Peppered Bacon In Bag -...  [$17.97 avg/ea]\n45  [Indiana Kitchen Hardwood Smoked Bacon - 16 Ou...          [$5.49]\n46  [Fresh Thyme Fully Cooked Uncured Turkey Bacon...          [$3.99]\n47  [Applegate Organics Uncured Hickory Smoked Tur...          [$7.49]\n\n\n\n\n\nOutput"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_WrapUp.html",
    "href": "posts/Aaron_C_Week3/Week3_WrapUp.html",
    "title": "AI/Local Food Week 3 Wrap Up",
    "section": "",
    "text": "The currents project objectives for this week was to\n\nCatch up on any additional training.\nCollect and find data on heirloom tomatoes, eggs, and bacon.\nLearning how to do web scraping in python.\nBuilding programs to do web scraping"
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_WrapUp.html#works-in-progress",
    "href": "posts/Aaron_C_Week3/Week3_WrapUp.html#works-in-progress",
    "title": "AI/Local Food Week 3 Wrap Up",
    "section": "Works in Progress",
    "text": "Works in Progress\nAn excel sheet that contains a list of small bussineses of Iowa grocers that we had to go through and find places that had the data we wanted.\n\n\nThese are some examples of what we were looking for\n\n\nAlong with some manual data scraping. We started work on some data scraping programs (spiders). This image shows an example of the data we were able to scrape."
  },
  {
    "objectID": "posts/Aaron_C_Week3/Week3_WrapUp.html#dspg-questions",
    "href": "posts/Aaron_C_Week3/Week3_WrapUp.html#dspg-questions",
    "title": "AI/Local Food Week 3 Wrap Up",
    "section": "DSPG Questions",
    "text": "DSPG Questions\n\nAre there stores or market places that would be helpful for us to look into?\nIs anyone experienced in webscraping and if so there any advice that you have for us?"
  }
]